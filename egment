[1mdiff --git a/GPT_SoVITS/inference_webui.py b/GPT_SoVITS/inference_webui.py[m
[1mindex 72413f0..8fa031a 100644[m
[1m--- a/GPT_SoVITS/inference_webui.py[m
[1m+++ b/GPT_SoVITS/inference_webui.py[m
[36m@@ -311,8 +311,45 @@[m [mdef merge_short_text_in_array(texts, threshold):[m
             result[len(result) - 1] += text[m
     return result[m
 [m
[32m+[m[32mdef ref_wav2prompt_semantic(ref_wav_path,):[m
[32m+[m[32m    #å…¨é›¶çš„éŸ³é¢‘æ³¢å½¢æ•°ç»„[m
[32m+[m[32m    zero_wav = np.zeros([m
[32m+[m[32m        int(hps.data.sampling_rate * 0.3),[m
[32m+[m[32m        dtype=np.float16 if is_half == True else np.float32,[m
[32m+[m[32m    )[m
[32m+[m[32m    with torch.no_grad():[m
[32m+[m[32m        #æŠŠ ref éŸ³é¢‘é‡é‡‡æ ·åˆ° 16k[m
[32m+[m[32m        wav16k, sr = librosa.load(ref_wav_path, sr=16000)[m
[32m+[m[32m        if (wav16k.shape[0] > 160000 or wav16k.shape[0] < 48000):[m
[32m+[m[32m            raise OSError(i18n("å‚è€ƒéŸ³é¢‘åœ¨3~10ç§’èŒƒå›´å¤–ï¼Œè¯·æ›´æ¢ï¼"))[m
[32m+[m[32m        #numpy è½¬æ¢æˆ pytorch å¼ é‡[m
[32m+[m[32m        wav16k = torch.from_numpy(wav16k)[m
[32m+[m[32m        zero_wav_torch = torch.from_numpy(zero_wav)[m
[32m+[m[32m        if is_half == True:[m
[32m+[m[32m            wav16k = wav16k.half().to(device)[m
[32m+[m[32m            zero_wav_torch = zero_wav_torch.half().to(device)[m
[32m+[m[32m        else:[m
[32m+[m[32m            wav16k = wav16k.to(device)[m
[32m+[m[32m            zero_wav_torch = zero_wav_torch.to(device)[m
[32m+[m[32m        #æ‹¼èµ·æ¥[m
[32m+[m[32m        wav16k = torch.cat([wav16k, zero_wav_torch])[m
[32m+[m[32m        #è¿‡ä¸€éhubert[m
[32m+[m[32m        #ssl_model = cnhubert.get_model()[m
[32m+[m[32m        #ä½¿ç”¨ cn_hubert ï¼ŒåŸºäºŽwavé€å±‚encodeï¼ŒæŠ½å–è¯­éŸ³hubert è‡ªç›‘ç£å‘é‡[m
[32m+[m[32m        ssl_content = ssl_model.model(wav16k.unsqueeze(0))[[m
[32m+[m[32m            "last_hidden_state"[m
[32m+[m[32m        ].transpose([m
[32m+[m[32m            1, 2[m
[32m+[m[32m        )  # .float()[m
[32m+[m[32m        #vqæå–codebookï¼Ÿ  æå–éšè—ç‰¹å¾[m
[32m+[m[32m        #è¿‡  codebookï¼Œå¾—åˆ°å¯¹åº”wav çš„ codebook ids[m
[32m+[m[32m        codes = vq_model.extract_latent(ssl_content)[m
[32m+[m[32m        prompt_semantic = codes[0, 0][m
[32m+[m
[32m+[m
 #æŽ¨ç† TTS è¯­éŸ³å…¥å£[m
[31m-def get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language, how_to_cut=i18n("ä¸åˆ‡"), top_k=20, top_p=0.6, temperature=0.6, ref_free = False):[m
[32m+[m[32mdef get_tts_wav(ref_wav_path,ref_wav_path2, prompt_text,prompt_text2, prompt_language, text, text_language, how_to_cut=i18n("ä¸åˆ‡"), top_k=20, top_p=0.6, temperature=0.6, ref_free = False):[m
[32m+[m
     if prompt_text is None or len(prompt_text) == 0:[m
         ref_free = True[m
     t0 = ttime()[m
[36m@@ -331,14 +368,15 @@[m [mdef get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language,[m
     #ç»™text è‹¥å¼€å¤´æ— åˆ†éš”ç¬¦ ä¸” æ­£åˆ™å®ŒåŽç¬¬ä¸€ä¸ªçŸ­å¥é•¿åº¦å°äºŽ4 åœ¨ç¬¬ä¸€ä¸ªå­—ç¬¦åŠ ä¸Š"ã€‚"åˆ†éš”ç¬¦[m
     if (text[0] not in splits and len(get_first(text)) < 4): [m
         text = "ã€‚" + text if text_language != "en" else "." + text[m
[31m-    [m
     print(i18n("å®žé™…è¾“å…¥çš„ç›®æ ‡æ–‡æœ¬:"), text)[m
     #å…¨é›¶çš„éŸ³é¢‘æ³¢å½¢æ•°ç»„[m
     zero_wav = np.zeros([m
         int(hps.data.sampling_rate * 0.3),[m
         dtype=np.float16 if is_half == True else np.float32,[m
     )[m
[31m-    #æŽ¨ç†æ—¶ä¸è®¡ç®—æ¢¯åº¦[m
[32m+[m[32m    #æŽ¨ç†[m
[32m+[m[32m    #var in ref_wav_path is_half[m
[32m+[m[32m    #var out prompt_semantic[m
     with torch.no_grad():[m
         #æŠŠ ref éŸ³é¢‘é‡é‡‡æ ·åˆ° 16k[m
         wav16k, sr = librosa.load(ref_wav_path, sr=16000)[m
[36m@@ -351,7 +389,6 @@[m [mdef get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language,[m
             wav16k = wav16k.half().to(device)[m
             zero_wav_torch = zero_wav_torch.half().to(device)[m
         else:[m
[31m-            #æŒ‡å®šè®¡ç®—è®¾å¤‡[m
             wav16k = wav16k.to(device)[m
             zero_wav_torch = zero_wav_torch.to(device)[m
         #æ‹¼èµ·æ¥[m
[36m@@ -367,8 +404,8 @@[m [mdef get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language,[m
         #vqæå–codebookï¼Ÿ  æå–éšè—ç‰¹å¾[m
         #è¿‡  codebookï¼Œå¾—åˆ°å¯¹åº”wav çš„ codebook ids[m
         codes = vq_model.extract_latent(ssl_content)[m
[31m-[m
         prompt_semantic = codes[0, 0][m
[32m+[m[41m    [m
     t1 = ttime()[m
 [m
     if (how_to_cut == i18n("å‡‘å››å¥ä¸€åˆ‡")):[m
[36m@@ -388,7 +425,7 @@[m [mdef get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language,[m
     texts = merge_short_text_in_array(texts, 5)[m
     audio_opt = [][m
     if not ref_free:[m
[31m-        #text ids è½¬æ¢ä¸ºå‘éŸ³ phone idsï¼Œæ ¹æ®phone ids ç¼–ç  bert ç‰¹å¾ï¼Œå–bertæ¨¡åž‹å€’æ•°ç¬¬3å±‚tensorï¼ŒåŒæ—¶åŽ»æŽ‰SOS å’ŒEOS[m
[32m+[m[32m        #text ids è½¬æ¢ä¸ºå‘éŸ³ phone idsï¼Œæ ¹æ®phone ids ç¼–ç  bert ç‰¹å¾ï¼Œå–bertæ¨¡åž‹å€’æ•°ç¬¬3å±‚tensorï¼ŒåŒæ—¶åŽ»æŽ‰SOSå’ŒEOS[m
         phones1,bert1,norm_text1=get_phones_and_bert(prompt_text, prompt_language)[m
     [m
     for text in texts:[m
[36m@@ -401,7 +438,14 @@[m [mdef get_tts_wav(ref_wav_path, prompt_text, prompt_language, text, text_language,[m
         print(i18n("å‰ç«¯å¤„ç†åŽçš„æ–‡æœ¬(æ¯å¥):"), norm_text2)[m
         if not ref_free:[m
             bert = torch.cat([bert1, bert2], 1)[m
[32m+[m[32m            print("bert1:",bert1)[m
[32m+[m[32m            print("bert2:",bert2)[m
[32m+[m[32m            print("bert:",bert)[m
             all_phoneme_ids = torch.LongTensor(phones1+phones2).to(device).unsqueeze(0)[m
[32m+[m[32m            print("phone1:",phones1)[m
[32m+[m[32m            print("phone2:",phones2)[m
[32m+[m[32m            print("1+2:",all_phoneme_ids)[m
[32m+[m
         else:[m
             bert = bert2[m
             all_phoneme_ids = torch.LongTensor(phones2).to(device).unsqueeze(0)[m
[36m@@ -585,11 +629,19 @@[m [mwith gr.Blocks(title="GPT-SoVITS WebUI") as app:[m
             GPT_dropdown.change(change_gpt_weights, [GPT_dropdown], [])[m
         gr.Markdown(value=i18n("*è¯·ä¸Šä¼ å¹¶å¡«å†™å‚è€ƒä¿¡æ¯"))[m
         with gr.Row():[m
[31m-            inp_ref = gr.Audio(label=i18n("è¯·ä¸Šä¼ 3~10ç§’å†…å‚è€ƒéŸ³é¢‘ï¼Œè¶…è¿‡ä¼šæŠ¥é”™ï¼"), type="filepath")[m
[32m+[m[32m            with gr.Column():[m
[32m+[m[32m                inp_ref = gr.Audio(label=i18n("1è¯·ä¸Šä¼ 3~10ç§’å†…å‚è€ƒéŸ³é¢‘ï¼Œè¶…è¿‡ä¼šæŠ¥é”™ï¼"), type="filepath")[m
[32m+[m[32m                inp_ref2 = gr.Audio(label=i18n("2è¯·ä¸Šä¼ 3~10ç§’å†…å‚è€ƒéŸ³é¢‘ï¼Œè¶…è¿‡ä¼šæŠ¥é”™ï¼"), type="filepath")[m
[32m+[m[32m                inp_ref3 = gr.Audio(label=i18n("3è¯·ä¸Šä¼ 3~10ç§’å†…å‚è€ƒéŸ³é¢‘ï¼Œè¶…è¿‡ä¼šæŠ¥é”™ï¼"), type="filepath")[m
[32m+[m[32m                inp_ref4 = gr.Audio(label=i18n("4è¯·ä¸Šä¼ 3~10ç§’å†…å‚è€ƒéŸ³é¢‘ï¼Œè¶…è¿‡ä¼šæŠ¥é”™ï¼"), type="filepath")[m
[32m+[m
             with gr.Column():[m
                 ref_text_free = gr.Checkbox(label=i18n("å¼€å¯æ— å‚è€ƒæ–‡æœ¬æ¨¡å¼ã€‚ä¸å¡«å‚è€ƒæ–‡æœ¬äº¦ç›¸å½“äºŽå¼€å¯ã€‚"), value=False, interactive=True, show_label=True)[m
                 gr.Markdown(i18n("ä½¿ç”¨æ— å‚è€ƒæ–‡æœ¬æ¨¡å¼æ—¶å»ºè®®ä½¿ç”¨å¾®è°ƒçš„GPTï¼Œå¬ä¸æ¸…å‚è€ƒéŸ³é¢‘è¯´çš„å•¥(ä¸æ™“å¾—å†™å•¥)å¯ä»¥å¼€ï¼Œå¼€å¯åŽæ— è§†å¡«å†™çš„å‚è€ƒæ–‡æœ¬ã€‚"))[m
[31m-                prompt_text = gr.Textbox(label=i18n("å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬"), value="")[m
[32m+[m[32m                prompt_text = gr.Textbox(label=i18n("å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬1"), value="")[m
[32m+[m[32m                prompt_text2 = gr.Textbox(label=i18n("å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬2"), value="")[m
[32m+[m[32m                prompt_text3 = gr.Textbox(label=i18n("å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬3"), value="")[m
[32m+[m[32m                prompt_text4 = gr.Textbox(label=i18n("å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬4"), value="")[m
             prompt_language = gr.Dropdown([m
                 label=i18n("å‚è€ƒéŸ³é¢‘çš„è¯­ç§"), choices=[i18n("ä¸­æ–‡"), i18n("è‹±æ–‡"), i18n("æ—¥æ–‡"), i18n("ä¸­è‹±æ··åˆ"), i18n("æ—¥è‹±æ··åˆ"), i18n("å¤šè¯­ç§æ··åˆ")], value=i18n("ä¸­æ–‡")[m
             )[m
[36m@@ -615,7 +667,7 @@[m [mwith gr.Blocks(title="GPT-SoVITS WebUI") as app:[m
 [m
         inference_button.click([m
             get_tts_wav,[m
[31m-            [inp_ref, prompt_text, prompt_language, text, text_language, how_to_cut, top_k, top_p, temperature, ref_text_free],[m
[32m+[m[32m            [inp_ref,inp_ref2, prompt_text, prompt_text2,prompt_language, text, text_language, how_to_cut, top_k, top_p, temperature, ref_text_free],[m
             [output],[m
         )[m
 [m
